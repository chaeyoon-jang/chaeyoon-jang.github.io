---
layout: post
title:  "Verbalized Confidence Triggers Self-Verification: Emergent Behavior Without Explicit Reasoning Supervision"
date:   2025-06-04 00:00:00 +00:00
image: /images/vconf25.png
categories: research
author: "Chaeyun Jang"
authors: "<strong>Chaeyun Jang</strong>, Moonseok Choi, Yegon Kim, Hyungi Lee, Juho Lee"
venue: "ICML 2025 R2-FM Workshop"
arxiv: https://arxiv.org/abs/2506.03723
website: https://scholar.google.com/citations?view_op=view_citation&hl=ko&user=pFo8UcAAAAAJ&citation_for_view=pFo8UcAAAAAJ:UeHWp8X0CEIC
---
We show that fine-tuning LLMs with only scalar confidence labels elicits **self-verification behavior** without explicit reasoning supervision. Our method improves calibration and accuracy on GSM8K, MATH-500, and ARC-Challenge, while enhancing interpretability by aligning reasoning with confidence.